{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from PIL import Image\n",
    "import os"
   ],
   "id": "e65dfdc502cd7109"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "file_names = os.listdir(\"../amos22/Train/label\")\n",
    "slice_nums = [int(name.split(\"_\")[1]) for name in file_names]\n",
    "slice_nums = set(slice_nums)\n",
    "scans_list = [[name for name in file_names if int(name.split(\"_\")[1]) == i] for i in slice_nums]"
   ],
   "id": "eb655f84d0da8bb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "key = lambda x : int(x.split(\"slice\")[1].split(\".\")[0])\n",
    "for list in scans_list:\n",
    "    list.sort(key=key)"
   ],
   "id": "bd959f574fd877c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_cuts = 14\n",
    "wanted_cuts = []\n",
    "for list_of_slices in scans_list:\n",
    "    length = len(list_of_slices)\n",
    "    offset = int(length / num_cuts)\n",
    "    slices = []\n",
    "    for i in range(num_cuts):\n",
    "        slices.append(list_of_slices[i*offset])\n",
    "\n",
    "    wanted_cuts.append(slices)"
   ],
   "id": "9fe9d015a407c691"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the path where images are stored\n",
    "DATASET_PATH = \"../amos22/Train/label\"  # Change this to your dataset path\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load an image as a NumPy array (assuming grayscale labeled segmentation masks).\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    return np.array(img)  # Shape: (H, W)\n",
    "\n",
    "def compute_most_frequent_class(slices_list, dataset_path, with_background=True):\n",
    "    \"\"\"\n",
    "    Compute the most frequent class per pixel for each relative slice position.\n",
    "\n",
    "    Args:\n",
    "        slices_list: List of lists containing image filenames.\n",
    "        dataset_path: Root path where images are stored.\n",
    "        with_background (bool): If False, ignores background (0) when computing the most common class.\n",
    "\n",
    "    Returns:\n",
    "        dict: {slice_index: most_frequent_class_array} mapping each relative slice index to its most frequent labels.\n",
    "    \"\"\"\n",
    "    num_scans = len(slices_list)\n",
    "    num_slices = len(slices_list[0])  # Assuming all scans have the same number of slices\n",
    "\n",
    "    most_frequent_slices = {}  # Dictionary mapping relative slice index to its class distribution\n",
    "\n",
    "    for slice_idx in range(num_slices):\n",
    "        slice_images = []  # Stores images from all scans for the current slice index\n",
    "\n",
    "        for scan in slices_list:\n",
    "            image_path = os.path.join(dataset_path, scan[slice_idx])\n",
    "            slice_images.append(load_image(image_path))\n",
    "\n",
    "        slice_images = np.stack(slice_images, axis=0)  # Shape: (num_scans, H, W)\n",
    "\n",
    "        if with_background:\n",
    "            # Compute the most frequent class including background (label 0)\n",
    "            most_frequent_class, _ = mode(slice_images, axis=0, keepdims=False)\n",
    "        else:\n",
    "            # Ignore background (label 0) when computing the most common class\n",
    "            mask_nonzero = slice_images != 0  # Mask for non-background values\n",
    "            filtered_slices = np.where(mask_nonzero, slice_images, np.nan)  # Replace 0 with NaN\n",
    "\n",
    "            # Compute mode while ignoring NaN (background)\n",
    "            most_frequent_class = np.apply_along_axis(\n",
    "                lambda x: np.nan if np.all(np.isnan(x)) else np.bincount(x[~np.isnan(x)].astype(int)).argmax(),\n",
    "                axis=0,\n",
    "                arr=filtered_slices\n",
    "            )\n",
    "\n",
    "            # Assign background (0) to pixels where the only value was 0 across all scans\n",
    "            only_background_pixels = np.all(slice_images == 0, axis=0)\n",
    "            most_frequent_class[only_background_pixels] = 0\n",
    "\n",
    "        most_frequent_slices[slice_idx * 10] = most_frequent_class.squeeze().astype(int)  # Store with relative index\n",
    "\n",
    "    return most_frequent_slices  # Dictionary of {relative slice index: (H, W) array}\n",
    "\n",
    "def plot_slices(most_frequent_slices, ncols=5):\n",
    "    \"\"\"\n",
    "    Plot each computed \"average\" slice.\n",
    "\n",
    "    Args:\n",
    "        most_frequent_slices (dict): Dictionary of {slice_position: 2D array} representing\n",
    "                                     the most frequent class per relative slice.\n",
    "        ncols (int): Number of columns per row in the plot.\n",
    "    \"\"\"\n",
    "    # Sort slices by their relative position\n",
    "    sorted_keys = sorted(most_frequent_slices.keys())  # Sorted slice positions\n",
    "    sorted_slices = [most_frequent_slices[key] for key in sorted_keys]  # Corresponding images\n",
    "\n",
    "    num_slices = len(sorted_slices)\n",
    "    nrows = (num_slices + ncols - 1) // ncols  # Compute number of rows\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 2, nrows * 2))\n",
    "\n",
    "    # Flatten axes if there are multiple rows\n",
    "    axes = axes.flatten() if isinstance(axes, np.ndarray) else [axes]\n",
    "\n",
    "    for i in range(num_slices):\n",
    "        axes[i].imshow(sorted_slices[i], cmap=\"jet\", interpolation=\"nearest\")\n",
    "        axes[i].set_title(f\"Slice {(100/num_slices * i):.2f}%\")  # Show actual slice position\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Hide unused subplot axes\n",
    "    for i in range(num_slices, len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "aa4980f97dd29790"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Run the processing\n",
    "most_frequent_slices = compute_most_frequent_class(wanted_cuts, DATASET_PATH, with_background=True)\n",
    "plot_slices(most_frequent_slices, ncols=5)"
   ],
   "id": "dc1eb4961c46aaf7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "most_frequent_slices = compute_most_frequent_class(wanted_cuts, DATASET_PATH, with_background=False)\n",
    "plot_slices(most_frequent_slices, ncols=5)"
   ],
   "id": "813bca798e7574ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_iou(prediction, ground_truth, ignore_background=True):\n",
    "    \"\"\"\n",
    "    Compute the Intersection over Union (IoU) for each class in a segmentation map.\n",
    "\n",
    "    Args:\n",
    "        prediction (np.ndarray): 2D array representing predicted segmentation.\n",
    "        ground_truth (np.ndarray): 2D array representing ground truth segmentation.\n",
    "        ignore_background (bool): If True, ignores background (class 0) when computing mean IoU.\n",
    "\n",
    "    Returns:\n",
    "        iou_per_class (dict): IoU values for each class.\n",
    "        mean_iou (float): Mean IoU across all classes.\n",
    "    \"\"\"\n",
    "    unique_classes = np.union1d(np.unique(prediction), np.unique(ground_truth))  # Only consider present classes\n",
    "    iou_per_class = {}\n",
    "\n",
    "    for cls in unique_classes[:16]:\n",
    "        if ignore_background and cls == 0:\n",
    "            continue  # Skip background if requested\n",
    "\n",
    "        intersection = np.sum((prediction == cls) & (ground_truth == cls))\n",
    "        union = np.sum((prediction == cls) | (ground_truth == cls))\n",
    "\n",
    "        iou_per_class[cls] = intersection / union if union > 0 else float(\"nan\")  # Avoid divide-by-zero\n",
    "\n",
    "    # Compute mean IoU only over valid classes\n",
    "    valid_ious = [iou for iou in iou_per_class.values() if not np.isnan(iou)]\n",
    "    mean_iou = np.mean(valid_ious) if valid_ious else 0.0\n",
    "\n",
    "    return iou_per_class, mean_iou\n",
    "\n",
    "\n",
    "def predict_slice_label(slice_name, most_frequent_slices):\n",
    "    \"\"\"\n",
    "    Predict the label map of a given slice based on the closest relative slice.\n",
    "\n",
    "    Args:\n",
    "        slice_name (str): The filename of the input slice.\n",
    "        most_frequent_slices (dict): Precomputed dictionary of most common labels per relative slice.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Predicted label map for the given slice.\n",
    "    \"\"\"\n",
    "    # Extract slice index from filename (assuming format \"amos_xxxx_sliceYY.png\")\n",
    "    slice_idx = int(slice_name.split('_slice')[-1].split('.')[0])\n",
    "\n",
    "    # Find the closest relative slice in the dictionary\n",
    "    closest_slice = min(most_frequent_slices.keys(), key=lambda x: abs(x - slice_idx))\n",
    "\n",
    "    # Return the precomputed most common label map\n",
    "    return most_frequent_slices[closest_slice]"
   ],
   "id": "56bdb4ac6d41f8e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Predict labels for a new slice\n",
    "img_path = \"amos_0001_slice52.png\"\n",
    "predicted_labels = predict_slice_label(img_path, most_frequent_slices)\n",
    "\n",
    "# Load the corresponding ground truth segmentation\n",
    "ground_truth_path = os.path.join(DATASET_PATH, img_path)\n",
    "ground_truth_labels = load_image(ground_truth_path)\n",
    "iou_per_class, mean_iou = compute_iou(predicted_labels, ground_truth_labels, ignore_background=False)\n",
    "\n",
    "# Plot side-by-side comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Predicted Segmentation\n",
    "axes[0].imshow(predicted_labels, cmap=\"jet\", interpolation=\"nearest\")\n",
    "axes[0].set_title(\"Predicted Segmentation\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Ground Truth Segmentation\n",
    "axes[1].imshow(ground_truth_labels, cmap=\"jet\", interpolation=\"nearest\")\n",
    "axes[1].set_title(\"Ground Truth Segmentation\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(mean_iou)\n",
    "for item in iou_per_class.items():\n",
    "    print(item)\n",
    "\n",
    "print(\"Unique labels in prediction:\", np.unique(predicted_labels))\n",
    "print(\"Unique labels in ground truth:\", np.unique(ground_truth_labels))\n",
    "\n",
    "print(\"Prediction shape:\", predicted_labels.shape)\n",
    "print(\"Ground truth shape:\", ground_truth_labels.shape)\n",
    "\n",
    "overlapping_pixels = np.any(predicted_labels == ground_truth_labels)\n",
    "print(\"Any overlapping pixels:\", overlapping_pixels)"
   ],
   "id": "db712afdeb07fb00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def compute_average_iou(folder_path, most_frequent_slices, ignore_background=True):\n",
    "    \"\"\"\n",
    "    Compute the average IoU for each class across all images in a folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the dataset folder containing segmentation masks.\n",
    "        most_frequent_slices (dict): Precomputed most frequent class segmentations.\n",
    "        ignore_background (bool): If True, ignores background class (0) when computing mean IoU.\n",
    "\n",
    "    Returns:\n",
    "        avg_iou_per_class (dict): Average IoU per class across all images.\n",
    "        overall_mean_iou (float): Mean IoU across all classes and images.\n",
    "    \"\"\"\n",
    "    iou_per_class_total = {}  # To store sum of IoUs per class\n",
    "    count_per_class = {}  # Count of images where the class appears\n",
    "    num_images = 0  # Count total images processed\n",
    "\n",
    "    for img_name in tqdm(os.listdir(folder_path)):\n",
    "        if not img_name.endswith(\".png\"):  # Ensure only images are processed\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        ground_truth_labels = load_image(img_path)  # Load ground truth segmentation\n",
    "        predicted_labels = predict_slice_label(img_name, most_frequent_slices)  # Predict segmentation\n",
    "\n",
    "        # Compute IoU\n",
    "        iou_per_class, _ = compute_iou(predicted_labels, ground_truth_labels, ignore_background=ignore_background)\n",
    "\n",
    "        # Aggregate IoU values\n",
    "        for cls, iou in iou_per_class.items():\n",
    "            if np.isnan(iou):\n",
    "                continue  # Ignore NaN values\n",
    "\n",
    "            if cls not in iou_per_class_total:\n",
    "                iou_per_class_total[cls] = 0\n",
    "                count_per_class[cls] = 0\n",
    "\n",
    "            iou_per_class_total[cls] += iou\n",
    "            count_per_class[cls] += 1\n",
    "\n",
    "        num_images += 1\n",
    "\n",
    "    # Compute the final average IoU per class\n",
    "    avg_iou_per_class = {cls: (iou_per_class_total[cls] / count_per_class[cls])\n",
    "                         for cls in iou_per_class_total.keys()}\n",
    "\n",
    "    # Compute overall mean IoU across all images and classes\n",
    "    valid_ious = [iou for iou in avg_iou_per_class.values()]  # Avoid using `list()`\n",
    "    overall_mean_iou = np.mean(valid_ious) if valid_ious else 0.0\n",
    "\n",
    "    return avg_iou_per_class, overall_mean_iou\n",
    "\n",
    "# Folder containing ground truth segmentations\n",
    "dataset_folder = r\"/Users/yp/PycharmProjects/AMOS/amos22/Validation/label\"\n",
    "\n",
    "# Compute IoU across the dataset\n",
    "avg_iou_per_class, overall_mean_iou = compute_average_iou(dataset_folder, most_frequent_slices, ignore_background=False)\n",
    "\n",
    "# Print results\n",
    "print(f\"Overall Mean IoU: {overall_mean_iou:.4f}\")\n",
    "print(\"Average IoU per class across dataset:\")\n",
    "for cls, iou in avg_iou_per_class.items():\n",
    "    print(f\"Class {cls}: {iou:.4f}\")\n"
   ],
   "id": "a07fd637ab10c720"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def compute_label_distribution(folder_path):\n",
    "    \"\"\"\n",
    "    Compute the relative frequency of each label across all images in a folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the dataset folder containing segmentation masks.\n",
    "\n",
    "    Returns:\n",
    "        label_distribution (dict): Dictionary where keys are class labels and values are their relative frequencies.\n",
    "    \"\"\"\n",
    "    label_counts = defaultdict(int)\n",
    "    total_pixels = 0\n",
    "\n",
    "    for img_name in tqdm(os.listdir(folder_path)):\n",
    "        if not img_name.endswith(\".png\"):  # Ensure only image files are processed\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        ground_truth_labels = load_image(img_path)  # Load segmentation mask\n",
    "\n",
    "        unique, counts = np.unique(ground_truth_labels, return_counts=True)\n",
    "        for label, count in zip(unique, counts):\n",
    "            label_counts[label] += count\n",
    "            total_pixels += count  # Accumulate total pixel count\n",
    "\n",
    "    # Compute relative frequency\n",
    "    label_distribution = {label: count / total_pixels for label, count in label_counts.items()}\n",
    "    return label_distribution\n",
    "\n",
    "def plot_label_distribution(label_distribution):\n",
    "    \"\"\"\n",
    "    Plot a bar chart of label distribution.\n",
    "\n",
    "    Args:\n",
    "        label_distribution (dict): Dictionary where keys are class labels and values are their relative frequencies.\n",
    "    \"\"\"\n",
    "    labels = [label for label in label_distribution.keys()]  # Explicitly create list\n",
    "    frequencies = [freq for freq in label_distribution.values()]  # Explicitly create list\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(labels, frequencies, color='skyblue')\n",
    "    plt.xlabel(\"Class Label\")\n",
    "    plt.ylabel(\"Relative Frequency\")\n",
    "    plt.title(\"Relative Amount of Labels in the Dataset\")\n",
    "    plt.xticks(labels)  # Ensure all labels are shown\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    plt.show()"
   ],
   "id": "91893d6d814a518e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Path to dataset folder containing segmentation masks\n",
    "dataset_folder = r\"/Users/yp/PycharmProjects/AMOS/amos22/Validation/label\"\n",
    "\n",
    "# Compute and plot label distribution\n",
    "label_distribution = compute_label_distribution(DATASET_PATH)"
   ],
   "id": "8fceddd2c0196463"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_label_distribution(label_distribution)",
   "id": "bb94ff85a633818d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9a037d4d9023a9e4"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
